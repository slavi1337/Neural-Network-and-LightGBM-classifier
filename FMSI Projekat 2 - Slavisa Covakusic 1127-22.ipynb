{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkmikVm2P6b7"
      },
      "source": [
        "# Projekat 2 - Formalne metode u softverskom inženjerstvu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Uvod\n",
        "\n",
        "Ovaj projektni zadatak ima za cilj poređenje performansi neuronske mreže i LightGBM klasifikatora na RCV1 skupu podataka.\n",
        "Neuronska mreža će biti istrenirana sa jednim skrivenim slojem sa 512 neurona, dok će LightGBM model biti optimizovan korišćenjem Optuna biblioteke za pretragu hiperparametara. Performanse oba modela će biti poređene na osnovu preciznosti i odziva.\n",
        "\n",
        "### Pokretanje projekta\n",
        "\n",
        "Za pokretanje ovog projekta potrebno je imati instaliran Python 3.12.2 kako bi se osiguralo da radi sve kao kod mene.\n",
        "\n",
        "Preporučene specifikacije računara:\n",
        "\n",
        "- **Procesor (CPU):** Intel Core i5 ili ekvivalentan AMD procesor\n",
        "- **Memorija (RAM):** 16 GB RAM\n",
        "- **Disk:** SSD sa najmanje 100 GB slobodnog prostora\n",
        "\n",
        "Projekat se može pokrenuti na CPU, ali za brže treniranje preporučuje se korišćenje GPU-a, uz minimalne korekcije u kodu.\n",
        "\n",
        "\n",
        "### Instalacija potrebnih biblioteka\n",
        "\n",
        "Za pokretanje ovog projekta, potrebno je instalirati sledeće biblioteke (mi smo ih instalirali u sklopu laboratorijskih vježbi):\n",
        "\n",
        "- `scikit-learn`\n",
        "- `scipy`\n",
        "- `numpy`\n",
        "- `torch`\n",
        "- `lightgbm`\n",
        "- `optuna`\n",
        "\n",
        "Možete instalirati ove biblioteke koristeći sledeću komandu u CMD-u:\n",
        "\n",
        "```bash\n",
        "pip install scikit-learn scipy numpy torch lightgbm optuna\n",
        "\n",
        "_______________________________________________________________________________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Učitavanje i priprema podataka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9nodOaijK1v2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_rcv1\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ucitavanje RCV1 dataset-a\n",
        "rcv1 = fetch_rcv1()\n",
        "\n",
        "# Ulazni podaci\n",
        "X = rcv1.data\n",
        "\n",
        "# Ciljne vrijednosti\n",
        "y = rcv1.target\n",
        "\n",
        "# Dijeljenje podataka na trening i testni skup 50% - 50%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Implementacija neuronske mreže"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xj88QueiPvDl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "import scipy.sparse as sp\n",
        "\n",
        "# Morao sam ovako jer sam dobijao memory error kad sam kovertovao klasicno\n",
        "class SparseDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    \n",
        "    # Vraca broj uzoraka u datasetu\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    # Vraca uzorak i njegovu ciljnu vrijednost na osnovu indeksa\n",
        "    def __getitem__(self, idx):\n",
        "        # Konverzija sparse matrice u gustu i izbacivanje dimenzije\n",
        "        x = self.X[idx].toarray().squeeze()\n",
        "        y = self.y[idx].toarray().squeeze()\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 512)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(512, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Kreiranje DataLoader-a za trening i test skupove\n",
        "train_dataset = SparseDataset(X_train, y_train)\n",
        "test_dataset = SparseDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "output_dim = y_train.shape[1]\n",
        "model = SimpleNN(input_dim, output_dim)\n",
        "\n",
        "# Funkcija greske za multilabel klasifikaciju\n",
        "# Vidio na https://stackoverflow.com/questions/59336899/which-loss-function-and-metrics-to-use-for-multi-label-classification-with-very\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Treniranje neuronske mreže"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1RBE9t-oQUGq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Precision: 0.9073, Recall: 0.8208\n",
            "Epoch [2/5], Precision: 0.9010, Recall: 0.8344\n",
            "Epoch [3/5], Precision: 0.8931, Recall: 0.8401\n",
            "Epoch [4/5], Precision: 0.8891, Recall: 0.8375\n",
            "Epoch [5/5], Precision: 0.8825, Recall: 0.8377\n"
          ]
        }
      ],
      "source": [
        "\n",
        "num_epochs = 5\n",
        "best_precision = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    # Itr kroz svaki batch u trening skupu\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        for data, target in test_loader:\n",
        "            outputs = model(data)\n",
        "            predictions = torch.sigmoid(outputs).round()\n",
        "            y_true.extend(target.numpy())\n",
        "            y_pred.extend(predictions.numpy())\n",
        "\n",
        "        precision = precision_score(np.array(y_true), np.array(y_pred), average='micro')\n",
        "        recall = recall_score(np.array(y_true), np.array(y_pred), average='micro')\n",
        "\n",
        "        if precision > best_precision:\n",
        "            best_precision = precision\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Precision: {precision:.4f}, Recall: {recall:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23raTzUgQGet"
      },
      "source": [
        "### 4. Treniranje LightGBM klasifikatora sa Optuna bibliotekom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I30Ytsu_Pxp5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-29 11:42:29,670] A new study created in memory with name: no-name-6ca5ad6c-1412-4003-9fea-add78fb51742\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Broj klasa: 103\n",
            "Training until validation scores don't improve for 5 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[50]\tvalid_0's multi_logloss: 2.21506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-29 12:10:43,147] Trial 0 finished with value: 0.35751491147593156 and parameters: {'learning_rate': 0.0020024383282386355, 'num_leaves': 103, 'max_depth': 7, 'feature_fraction': 0.8441809732147931, 'bagging_fraction': 0.82269670434411}. Best is trial 0 with value: 0.35751491147593156.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 5 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[50]\tvalid_0's multi_logloss: 2.11053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-29 12:28:13,293] Trial 1 finished with value: 0.45962899700900284 and parameters: {'learning_rate': 0.0035195745803832212, 'num_leaves': 94, 'max_depth': 4, 'feature_fraction': 0.7754985367165826, 'bagging_fraction': 0.8711515501074998}. Best is trial 1 with value: 0.45962899700900284.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 5 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[47]\tvalid_0's multi_logloss: 1.00386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-29 12:50:32,581] Trial 2 finished with value: 0.7693923775568302 and parameters: {'learning_rate': 0.03771153693025783, 'num_leaves': 101, 'max_depth': 5, 'feature_fraction': 0.909732921629326, 'bagging_fraction': 0.8236992893643755}. Best is trial 2 with value: 0.7693923775568302.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 5 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[50]\tvalid_0's multi_logloss: 1.32793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-29 13:09:24,714] Trial 3 finished with value: 0.7115415693908858 and parameters: {'learning_rate': 0.01744440871588926, 'num_leaves': 25, 'max_depth': 4, 'feature_fraction': 0.997133648147889, 'bagging_fraction': 0.9833239284239321}. Best is trial 2 with value: 0.7693923775568302.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 5 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[50]\tvalid_0's multi_logloss: 0.862909\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-29 13:53:13,027] Trial 4 finished with value: 0.8026986104170241 and parameters: {'learning_rate': 0.028353039884590363, 'num_leaves': 113, 'max_depth': 11, 'feature_fraction': 0.9168549463388005, 'bagging_fraction': 0.7179470646848696}. Best is trial 4 with value: 0.8026986104170241.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 5 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[50]\tvalid_0's multi_logloss: 1.33778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-29 14:31:33,388] Trial 5 finished with value: 0.7562971305820138 and parameters: {'learning_rate': 0.00985987551511969, 'num_leaves': 74, 'max_depth': 12, 'feature_fraction': 0.9229858758597357, 'bagging_fraction': 0.9678347639812017}. Best is trial 4 with value: 0.8026986104170241.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 5 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[49]\tvalid_0's multi_logloss: 0.890921\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-29 15:06:00,900] Trial 6 finished with value: 0.7933800257081552 and parameters: {'learning_rate': 0.02952102482015001, 'num_leaves': 125, 'max_depth': 8, 'feature_fraction': 0.9147257157515503, 'bagging_fraction': 0.907971964279543}. Best is trial 4 with value: 0.8026986104170241.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 5 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[50]\tvalid_0's multi_logloss: 2.15266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-29 15:31:04,005] Trial 7 finished with value: 0.38323549813901797 and parameters: {'learning_rate': 0.00234272496475997, 'num_leaves': 38, 'max_depth': 8, 'feature_fraction': 0.8123605133836813, 'bagging_fraction': 0.99841746342673}. Best is trial 4 with value: 0.8026986104170241.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 5 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[50]\tvalid_0's multi_logloss: 0.852802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-29 16:09:26,699] Trial 8 finished with value: 0.8034594126904803 and parameters: {'learning_rate': 0.02869112969714743, 'num_leaves': 75, 'max_depth': 12, 'feature_fraction': 0.810412097404499, 'bagging_fraction': 0.790699861028308}. Best is trial 8 with value: 0.8034594126904803.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 5 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[50]\tvalid_0's multi_logloss: 1.71214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-29 16:48:33,128] Trial 9 finished with value: 0.6759877376574749 and parameters: {'learning_rate': 0.005017481841806167, 'num_leaves': 86, 'max_depth': 13, 'feature_fraction': 0.9240857290334837, 'bagging_fraction': 0.7202895036862704}. Best is trial 8 with value: 0.8034594126904803.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 5 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[50]\tvalid_0's multi_logloss: 0.852802\n",
            "Najbolja preciznost sa LightGBM: 0.8035\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "import optuna\n",
        "\n",
        "# U gustu, da bi bio kompatibilan\n",
        "y = rcv1.target.toarray()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "# Konvertovanje u 1D niz, iz matrice zbog multiclass\n",
        "y_train_array = np.argmax(y_train, axis=1) \n",
        "y_test_array = np.argmax(y_test, axis=1) \n",
        "\n",
        "# Br klasa u RCV1\n",
        "num_classes = y.shape[1]\n",
        "\n",
        "print(f'Broj klasa: {num_classes}')\n",
        "\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'multiclass',\n",
        "        'num_class': num_classes,\n",
        "        'metric': 'multi_logloss',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "\n",
        "        # Odabrao sam ove vrijednosti za learning_rate jer mi je djelovao kao optimalan\n",
        "        # Sa lr=0.001 i njemu blizu vrijednostima model moze uciti polako, ali sigurno, ali ce mu trebati vise vremena za ucenje\n",
        "        # sa lr=0.05 i njemu blizu vrijednostima model moze uciti brze\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05, log=True),\n",
        "\n",
        "        # Za gornju granicu sam izabrao prvo izabrao 256 kao na casu, ali mi se model jako sporo trenirao\n",
        "        # A preciznost mu je ostala ista kao i sa tom vrijednoscu kad sam stavio 160, a brze se istrenirao\n",
        "        # Za donju granicu sam stavio 20, jer nisam imao ni na jednom trialu manje od 20 listova kad sam stavio da je minimalna vrijednost 2, \n",
        "        # a ubrzalo je proces treniranja \n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 160),\n",
        "\n",
        "        # Obrazlozenje isto kao gore, prvobitno je vrijednost bila 20, a modeli sa vecom vrijednoscu od 13 su imali slabiju preciznost\n",
        "        # Veca vrijednost moze dovesti do overfittinga, a manja pojednostavljuje stablo, tako da mi je ovaj opseg idealan bio da dobijem preciznost koju hocu\n",
        "        'max_depth': trial.suggest_int('max_depth', 4, 13),\n",
        "\n",
        "        # Vidio sa časa, ali sam povećao na 0.7 donju granicu zbog brzine treniranja\n",
        "\n",
        "        # Niža vrednost (0.7): Korišćenjem samo dela karakteristika u svakom boosting koraku, model je manje sklon overfittingu jer se ne oslanja previše na određene karakteristike.\n",
        "        # Viša vrednost (do 1.0): Korišćenje svih karakteristika može povećati preciznost modela jer model ima pristup svim informacijama iz podataka u svakom boosting koraku.\n",
        "        # Međutim, to takođe može povećati rizik od overfittinga, posebno ako podaci imaju mnogo karakteristika koje su međusobno zavisne\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.7, 1.0),\n",
        "        \n",
        "        # Niža vrednost (0.7): Korišćenjem samo dela podataka u svakom boosting koraku, model je manje sklon overfittingu jer se ne oslanja previše na određene uzorke iz trening seta.\n",
        "        # Ovo omogućava modelu da bude robusniji i poboljšava sposobnost generalizacije modela, jer se koristi različit set uzoraka u različitim koracima treninga.\n",
        "        # Viša vrednost (do 1.0): Korišćenje svih podataka može povećati preciznost modela jer model ima pristup svim informacijama iz podataka u svakom boosting koraku.\n",
        "        # Međutim, to takođe može povećati rizik od overfittinga\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.7, 1.0)\n",
        "    }\n",
        "\n",
        "    lgb_train = lgb.Dataset(X_train, label=y_train_array)\n",
        "    lgb_eval = lgb.Dataset(X_test, label=y_test_array, reference=lgb_train)\n",
        "\n",
        "    # Smanjio sam ES sa 10 na 5, isti rezultat sam dobio\n",
        "    # Smanjio sam broj boost rundi sa default 100 na 50, -||-\n",
        "    callbacks = [lgb.early_stopping(stopping_rounds=5)]\n",
        "    gbm = lgb.train(param, lgb_train, num_boost_round=50, valid_sets=lgb_eval, callbacks=callbacks)\n",
        "\n",
        "    y_pred = gbm.predict(X_test)\n",
        "    \n",
        "    # Morao dodati da se reshapuje, jer je bio typeerror\n",
        "    if y_pred.ndim == 1:\n",
        "        y_pred = y_pred.reshape(-1, num_classes)\n",
        "    \n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    precision = precision_score(y_test_array, y_pred_labels, average='micro')\n",
        "    return precision\n",
        "\n",
        "# Mora maximize, jer po defaultu minimizuje\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "best_params = study.best_params\n",
        "# Morao dodati pokazivalo da je error i da nema te parametre\n",
        "best_params['objective'] = 'multiclass'\n",
        "best_params['num_class'] = num_classes\n",
        "best_params['metric'] = 'multi_logloss'\n",
        "# Morao dodati da se ne ispisuju nepotrebne poruke\n",
        "best_params['verbosity'] = -1\n",
        "\n",
        "# Dodatno treniranje modela sa najboljim hiperparametrima\n",
        "lgb_train = lgb.Dataset(X_train, label=y_train_array)\n",
        "lgb_eval = lgb.Dataset(X_test, label=y_test_array, reference=lgb_train)\n",
        "final_gbm = lgb.train(best_params, lgb_train, num_boost_round=50, valid_sets=lgb_eval, callbacks=[lgb.early_stopping(stopping_rounds=5)])\n",
        "\n",
        "y_pred = final_gbm.predict(X_test)\n",
        "    \n",
        "if y_pred.ndim == 1:\n",
        "    y_pred = y_pred.reshape(-1, num_classes) # -1 da se automatski izracuna\n",
        "    \n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "final_precision = precision_score(y_test_array, y_pred_labels, average='micro')\n",
        "\n",
        "print(f'Najbolja preciznost sa LightGBM: {final_precision:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6r2BxFKQM8Q"
      },
      "source": [
        "## Poređenje performansi\n",
        "\n",
        "### Neuronska mreža VS LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qIHytIbQP0Bs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neuronska mreža - Precision: 0.9073, Recall: 0.8208\n",
            "Neuronska mreža je bolji model.\n"
          ]
        }
      ],
      "source": [
        "# Ucitavanje najboljeg modela od prije za neuronsku mrezu\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# Testiranje neuronske mreze\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for data, target in test_loader:\n",
        "        outputs = model(data)\n",
        "        predictions = torch.sigmoid(outputs).round()\n",
        "        y_true.extend(target.numpy())\n",
        "        y_pred.extend(predictions.numpy())\n",
        "\n",
        "nn_precision = precision_score(np.array(y_true), np.array(y_pred), average='micro')\n",
        "nn_recall = recall_score(np.array(y_true), np.array(y_pred), average='micro')\n",
        "\n",
        "print(f'Neuronska mreža - Precision: {nn_precision:.4f}, Recall: {nn_recall:.4f}')\n",
        "\n",
        "# Poredjenje sa LightGBM-ovom najboljom preciznoscu\n",
        "if nn_precision > final_precision:\n",
        "    print(\"Neuronska mreža je bolji model.\")\n",
        "else:\n",
        "    print(\"LightGBM je bolji model.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mislim da je Neuronska mreža bolji model u odnosu na LightGBM, jer je NN kompleksnija arhitektura i moze bolje da se trenira za ovako velik skup podataka. Takođe, za optimalan LightGBM klasifikator potrebno je sa optunom pretraziti sve moguce hiperparametre, sto je gotov nemoguće, pa zato mislim da su rezultati ovakvi kakvi jesu.\n",
        "Pokušavao sam na različite načine da optimizujem LightGBM, ali nikad nisam dobio preciznost vecu od 90% na ovom datasetu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Slaviša Čovakušić 1127/22"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
